{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Regularization, Perceptron, and Deep Neural Networks\n",
    "\n",
    "#### Edwin Ramirez, Kandace Mok, Darshil Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv \n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('movieData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>CriticsRating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre  CriticsRating  Watched\n",
       "0      1            1.2       -1\n",
       "1      1            3.5        1\n",
       "2      1            4.2        1\n",
       "3      2            3.9        1\n",
       "4      2            2.8       -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sico_df = pd.read_csv('siCoData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.889238</td>\n",
       "      <td>-0.334713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.898156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596540</td>\n",
       "      <td>0.870667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375349</td>\n",
       "      <td>-0.713875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083465</td>\n",
       "      <td>0.401115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0 -0.889238 -0.334713\n",
       "1  0.532539  0.898156\n",
       "2  0.596540  0.870667\n",
       "3 -0.375349 -0.713875\n",
       "4  0.083465  0.401115"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sico_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sico_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a learning scenario where the goal is to learn the target function $f(x) =\n",
    "sin(πx)$ for $−1 \\leq x \\leq +1$ from two points in the training sets. The two training\n",
    "points in $R^{2}$ have a uniform distribution between -1 and +1. You will create two\n",
    "models in linear hypothesis set $y = mx + b$: 1) unregularized, 2) weight-decay\n",
    "regularized (use L2 regularization with λ = 0.1).\n",
    "1. (5 points) Generate 10,000 hypotheses for each version. Report the average hypothesis $\\bar{g}(x)$ in each case.\n",
    "2. (5 points) Find and report bias2 for each model.\n",
    "3. (5 points) Find and report variance for each model\n",
    "4. (5 Points) For each case, plot $\\bar{g}(x)$ $\\pm \\sqrt{var}$ along with $\\bar{g}(x)$ and target function $f(x) = sin(πx)$. Which model will you choose? Why? **Round your answers to 3 decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(19999)\n",
    "X = list(range(20000))\n",
    "x_vals = [round(random.uniform(-1,1), 5) for val  in X]\n",
    "\n",
    "\n",
    "#Generate point coordinates (x, f(x))\n",
    "points = np.array([np.array([1, x, np.sin(np.pi*x)]) for x in x_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = points[0:10000]\n",
    "point2 = points[10000:]\n",
    "\n",
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unregularized(point_1, point_2):\n",
    "    x_ = np.array([point_1[0:2], point_2[0:2]])\n",
    "    y_ = np.array([point_1[2], point_2[2]])\n",
    "\n",
    "    w =  np.dot(np.dot(np.linalg.inv(np.dot(x_.T, x_)), x_.T), y_)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slopes and intercepts for all models\n",
    "unreg_w = np.array([unregularized(point1[i], point2[i]) for i in range(10000)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_b = np.mean(unreg_w.T[0])\n",
    "avg_m = np.mean(unreg_w.T[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unregularized Average Linear Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unregularized Average Linear Hypothesis: y = 0.806x + 0.006\n"
     ]
    }
   ],
   "source": [
    "print(\" Unregularized Average Linear Hypothesis: y = \" + str(round(avg_m,3)) +'x + ' + str(round(avg_b,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Avg Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(point_1, point_2):\n",
    "    X = np.array([point_1[0:2], point_2[0:2]])\n",
    "    y = np.array([point_1[2], point_2[2]])\n",
    "    lambda_I = np.identity(2)*0.1\n",
    "    #w = np.dot(np.dot(np.linalg.inv(np.add(np.dot(x_.T, x_), lambda_I)), x_.T), y_)\n",
    "    w = np.dot(inv(np.dot(X.T, X) + 0.1*np.identity(2)), np.dot(X.T, y))\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_w = np.array([regularize(point1[i], point2[i]) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_b_r = np.mean(reg_w.T[0])\n",
    "avg_m_r = np.mean(reg_w.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Regularized Average Linear Hypothesis: y = 0.639x + 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\" Regularized Average Linear Hypothesis: y = \" + str(round(avg_m_r,3)) +'x + ' + str(round(avg_b_r,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the $Bias^{2}$ of Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the $bias^{2}$ for all hypotheses, $g(x) = b$, we simply compute the differences between the target function values found in `points` and the average hypothesis $\\bar{g}$ and square them.\n",
    "\n",
    "$$bias(x) = \\bar{g}(x) - f(x) \\\\\n",
    "f(x) = sin(\\pi x) \\\\\n",
    "\\bar{g}(x) = mx + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get hypothesis values for all 20000 observations\n",
    "g_bar_unr = np.array([points[i][1]*avg_m + avg_b for i in range(20000)])\n",
    "g_bar_r = np.array([points[i][1]*avg_m_r + avg_b_r for i in range(20000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54770926,  0.92659691,  0.33284917, ..., -0.95332146,\n",
       "        0.15376539, -0.79059767])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = points.T[2]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16372238, 0.17540825, 0.15369748, ..., 0.40268885, 0.38265782,\n",
       "       0.05017104])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bias square values for unregularized model\n",
    "bias_sq_unr = np.power(g_bar_unr - y, 2)\n",
    "bias_sq_unr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18755444, 0.27627223, 0.05766185, ..., 0.48934072, 0.20868087,\n",
       "       0.11590344])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bias square values of regularized model\n",
    "bias_sq_r = np.power(g_bar_r - y, 2)\n",
    "bias_sq_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected bias for each model\n",
    "exp_bias_sq_unr = bias_sq_unr.mean()\n",
    "exp_bias_sq_r = bias_sq_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20287899566329956"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_bias_sq_unr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2290491749621517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_bias_sq_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unregularized Bias Squared: 0.203\n",
      "Regularized Bias Squared: 0.229\n"
     ]
    }
   ],
   "source": [
    "print(\"Unregularized Bias Squared: \" + str(round(exp_bias_sq_unr,3)))\n",
    "print(\"Regularized Bias Squared: \" + str(round(exp_bias_sq_r,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance of Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance for each hypothesis can be computed as the difference between the the hypothesis value $g(x)$ and average hypothesis, $\\bar{g}(x)$ squared:\n",
    "\n",
    "$$var = (g(x) - \\bar{g}(x))^2$$\n",
    "\n",
    "We compute the variance for all 10,000 hypotheses in the constant hypothesis set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30556566,  1.31243143])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unreg_w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22195373,  1.05953064])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00567949, 0.80630095])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_bar_un = np.array([avg_b, avg_m])\n",
    "g_bar_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00321631, 0.63875344])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_bar_r = np.array([avg_b_r, avg_m_r])\n",
    "g_bar_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeVar(avg_g, hypoth_g, point):\n",
    "    g1 = np.array([hypoth_g[i][1]*point + hypoth_g[i][0] for i in range(10000)])\n",
    "    g2 = avg_g[1]*point + avg_g[0]\n",
    "    \n",
    "    var = np.power(g1 - g2, 2)\n",
    "    mean_var = np.mean(var)\n",
    "    \n",
    "    return mean_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeVar(unreg_w, g_bar_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "progress = progressbar.ProgressBar()\n",
    "x_range = range(100)\n",
    "unreg_v = [computeVar(g_bar_un, unreg_w, points[i][1]) for i in progress(x_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "progress = progressbar.ProgressBar()\n",
    "x_range = range(100)\n",
    "reg_v = [computeVar(g_bar_r, reg_w, points[i][1]) for i in progress(x_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for Unregularized Linear Model:  1.681\n",
      "Variance for Unregularized Linear Model:  0.337\n"
     ]
    }
   ],
   "source": [
    "avg_v_un = round(np.mean(np.array(unreg_v)),3)\n",
    "avg_v_r = round(np.mean(np.array(reg_v)), 3)\n",
    "print(\"Variance for Unregularized Linear Model: \", avg_v_un)\n",
    "print(\"Variance for Unregularized Linear Model: \", avg_v_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define range of target function\n",
    "target_x = np.linspace(-1,1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00567949, 0.80630095])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_bar_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Consider the perceptron model in two dimensions with corresponding weights\n",
    "$w0$, $w1$, and $w2$ in figure 1.\n",
    "1. Determine the equation of the line in $x2 = mx1 + b$ form.\n",
    "2. Provide a set of values for $w0$, $w1$, and $w2$.\n",
    "3. Figure 2 shows a perceptron diagram that implements an AND logical operator. Draw a similar diagram for the perceptron model that corresponds to the boundary decision in figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "An online rental video company is interested in creating a model to make movie recommendations to one of its customers, Ms. X. As a consultant to this company, you are provided with the history of the movies that she accepted or rejected to watch. She makes her selections solely based on the movie genre and critic ratings. The data is in movieData.csv on Canvas.\n",
    "\n",
    "1. Train a perceptron that will create a linear boundary decision that will help the company to make future recommendations to Ms. X. After how many iterations does the algorithm converge?\n",
    "2. Upon creating a model, plot the boundary line along with all the data points and axes clearly marked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "In this problem you will use the data in siCoData.csv file to train a neural network. Use the backpropagation algorithm to train a 3-layer (input, hidden,output) neural network. Use stochastic gradient decent (SGD) technique and assume that the activation function for the hidden layer and output layer are tanh and linear, respectively. (You must write your own code for BP and SGD).\n",
    "\n",
    "1. The stopping criteria for training in this problem should be a combination of achieving a minimum in-sample error <br/> $E_{in} = \\frac{1}{N}\\sum_{n=1}^{N} e_{n}$ <br/> and reaching a maximum number of epochs (In this expression N is the number of observations in the data set and en is the error corresponding to each individual training point). Report the minimum Ein that you could achieve along with the related weights and number of iterations.\n",
    "\n",
    "2. Graph the original data (y vs. x) and the predicted values ($\\hat{y}$ vs. x) on two separate scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
